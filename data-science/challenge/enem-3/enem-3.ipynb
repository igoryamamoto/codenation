{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import seaborn as sns\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "# from sklearn import tree\n",
    "# from sklearn import ensemble\n",
    "# from sklearn import metrics\n",
    "\n",
    "import json\n",
    "import requests\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all data and generate report with dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"../data/test3.csv\")\n",
    "pp.ProfileReport(full_data).to_file(outputfile=\"./profile-test-full.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "- Manually select features based on previous report analysis\n",
    "- Load data, both to_predict and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"NU_NOTA_CN\", \"NU_NOTA_CH\", \"NU_NOTA_LC\", \"NU_NOTA_REDACAO\"]\n",
    "mt_cols = [\"CO_PROVA_MT\", \"TX_RESPOSTAS_MT\"]\n",
    "data_to_predict = pd.read_csv(\"../data/test3.csv\",\n",
    "                         usecols=[\"NU_INSCRICAO\"]+feature_cols+mt_cols)\n",
    "# pp.ProfileReport(data_to_predict).to_file(outputfile=\"./profile-test.html\")\n",
    "data_train = pd.read_csv(\"../data/train.csv\",\n",
    "                         usecols=[\"NU_INSCRICAO\", \"TX_GABARITO_MT\"]+feature_cols+mt_cols).dropna()\n",
    "# pp.ProfileReport(data_train).to_file(outputfile=\"./profile-train.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BCEDADCCAECEABABDCEBABEDAAECCDDBDBABDADB'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_predict.TX_RESPOSTAS_MT[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['A', 'B', 'C', 'D', 'E']\n",
    "def generate_answer():\n",
    "    answer = np.random.choice(options, 5, replace=True)\n",
    "    return ''.join(answer)\n",
    "random_answers = data_to_predict.TX_RESPOSTAS_MT.apply(lambda x: generate_answer())\n",
    "result = (\n",
    "    data_to_predict\n",
    "    .assign(TX_RESPOSTAS_MT=random_answers)\n",
    "    [[\"NU_INSCRICAO\", \"TX_RESPOSTAS_MT\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_guys = data_to_predict[data_to_predict.TX_RESPOSTAS_MT == 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC'].NU_INSCRICAO\n",
    "result[\"TX_RESPOSTAS_MT\"] = np.where(result[\"NU_INSCRICAO\"].isin(random_guys), 'CCCCC', result[\"TX_RESPOSTAS_MT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random using previous answers frequencies as probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['A', 'B', 'C', 'D', 'E']\n",
    "def generate_prob_answer(prev_answers):\n",
    "    prev_answers = np.array(list(prev_answers) + options)\n",
    "    unique, counts = np.unique(prev_answers, return_counts=True)\n",
    "    if '*' in unique:\n",
    "        answer = np.random.choice(options, 5, replace=True)\n",
    "        return ''.join(answer)\n",
    "    probs = counts/np.sum(counts)\n",
    "    answer = np.random.choice(options, 5, p=probs, replace=True)\n",
    "    return ''.join(answer)\n",
    "random_answers = data_to_predict.TX_RESPOSTAS_MT.apply(lambda x: generate_prob_answer(x))\n",
    "result = (\n",
    "    data_to_predict\n",
    "    .assign(TX_RESPOSTAS_MT=random_answers)\n",
    "    [[\"NU_INSCRICAO\", \"TX_RESPOSTAS_MT\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the gabarito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, indicies = np.unique(data_train.CO_PROVA_MT, return_index=True)\n",
    "gabaritos = np.array([])\n",
    "for i in indicies:\n",
    "    gabaritos = np.append(gabaritos, data_train.TX_GABARITO_MT.values[i])\n",
    "dict_mt_answers = dict(zip(unique, gabaritos))\n",
    "data_to_predict['TX_GABARITO_MT'] = data_to_predict.CO_PROVA_MT.replace(dict_mt_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everybody right answered last 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    data_to_predict\n",
    "    .assign(TX_RESPOSTAS_MT=lambda df: df.TX_GABARITO_MT.apply(lambda ans: ans[-5:]))\n",
    "    [[\"NU_INSCRICAO\", \"TX_RESPOSTAS_MT\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_guys = data_to_predict[data_to_predict.TX_RESPOSTAS_MT == 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC'].NU_INSCRICAO\n",
    "result[\"TX_RESPOSTAS_MT\"] = np.where(result[\"NU_INSCRICAO\"].isin(random_guys), 'CCCCC', result[\"TX_RESPOSTAS_MT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider previous right answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(seq1, seq2):  \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_answered = 40\n",
    "score = pd.Series([])\n",
    "for index, row in data_to_predict.iterrows():\n",
    "    score[index] = 1 - levenshtein(row['TX_RESPOSTAS_MT'], row['TX_GABARITO_MT'])/total_answered\n",
    "data_to_predict['SCORE'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>TX_RESPOSTAS_MT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060edb14439f3a7b0e736493d8dc5a45de16ed51</td>\n",
       "      <td>ADAEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63929f181ec794c4a94176b61f0d1def6f4799fe</td>\n",
       "      <td>EAEBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11c89c0cb5dc38aa74b242f702bf9df1edc23b5e</td>\n",
       "      <td>AECEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297931c1902ee1c5cd7bf2ee16b148dedd8e3a9f</td>\n",
       "      <td>EADBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14126c55c1c250f0d769526cf4d5383add31873d</td>\n",
       "      <td>ADAEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               NU_INSCRICAO TX_RESPOSTAS_MT\n",
       "0  060edb14439f3a7b0e736493d8dc5a45de16ed51           ADAEE\n",
       "1  63929f181ec794c4a94176b61f0d1def6f4799fe           EAEBA\n",
       "2  11c89c0cb5dc38aa74b242f702bf9df1edc23b5e           AECEC\n",
       "3  297931c1902ee1c5cd7bf2ee16b148dedd8e3a9f           EADBA\n",
       "4  14126c55c1c250f0d769526cf4d5383add31873d           ADAEA"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = ['A', 'B', 'C', 'D', 'E']\n",
    "def toss(prob):\n",
    "    return np.random.choice([True, False], p=[prob, 1-prob])\n",
    "\n",
    "def generate_prob_right_answer(row):\n",
    "    prev_answers = np.array(list(row['TX_RESPOSTAS_MT']) + options)\n",
    "    unique, counts = np.unique(prev_answers, return_counts=True)\n",
    "    if '*' in unique:\n",
    "        probs = np.ones(5)/5\n",
    "    else:\n",
    "        probs = counts/np.sum(counts)\n",
    "            \n",
    "    last_five_gabarito = row['TX_GABARITO_MT'][-5:]\n",
    "    score = row['SCORE']\n",
    "    answer = np.array([])\n",
    "    for i in range(5):\n",
    "        right_answer = last_five_gabarito[i]\n",
    "        if toss(score+0.2):\n",
    "            answer = np.append(answer, right_answer)\n",
    "        else:\n",
    "            random_answer = np.random.choice(options, 1, p=probs)\n",
    "            answer = np.append(answer, random_answer)\n",
    "    return ''.join(answer)\n",
    "\n",
    "answers = pd.Series([])\n",
    "for index, row in data_to_predict.iterrows():\n",
    "    answers[index] = generate_prob_right_answer(row)\n",
    "result = (\n",
    "    data_to_predict\n",
    "    .assign(TX_RESPOSTAS_MT=answers)\n",
    "    [[\"NU_INSCRICAO\", \"TX_RESPOSTAS_MT\"]]\n",
    ")\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_guys = data_to_predict[data_to_predict.TX_RESPOSTAS_MT == 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC'].NU_INSCRICAO\n",
    "result[\"TX_RESPOSTAS_MT\"] = np.where(result[\"NU_INSCRICAO\"].isin(random_guys), 'CCCCC', result[\"TX_RESPOSTAS_MT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = result.to_dict(\"records\")\n",
    "submission = {\n",
    "    \"token\": \"5cfb5e6838b5b71058949df3e8746d3ff1c31a73\",\n",
    "    \"email\": \"igor.a.r.y@gmail.com\",\n",
    "    \"answer\": answer\n",
    "}\n",
    "with open(\"submission.json\", \"w\") as fp:\n",
    "    json.dump(submission, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Post request to codenation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 23.193749999999998}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.codenation.com.br/v1/user/acceleration/data-science/challenge/enem-3/submit'\n",
    "r = requests.post(url, json=submission)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
